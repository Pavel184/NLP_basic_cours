{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "Homework_lesson_2.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yl8rn233jtkT"
      },
      "source": [
        "Осуществим предобработку данных с Твиттера, чтобы отчищенный данные в дальнейшем использовать для задачи классификации. Данный датасет содержит негативные (label = 1) и нейтральные (label = 0) высказывания.\n",
        "Для работы объединим train_df и test_df.\n",
        "\n",
        "Задания:\n",
        "\n",
        "1) Удалим @user из всех твитов с помощью паттерна \"@[\\w]*\". Для этого создадим функцию: \n",
        " - для того, чтобы найти все вхождения паттерна в тексте, необходимо использовать re.findall(pattern, input_txt)\n",
        " - для для замены @user на пробел, необходимо использовать re.sub()\n",
        "\n",
        "2) Изменим регистр твитов на нижний с помощью .lower().\n",
        "\n",
        "3) Заменим сокращения с апострофами (пример: ain't, can't) на пробел, используя apostrophe_dict. Для этого необходимо сделать функцию: для каждого слова в тексте проверить (for word in text.split()), если слово есть в словаре apostrophe_dict в качестве ключа (сокращенного слова), то заменить ключ на значение (полную версию слова).\n",
        "\n",
        "4) Заменим сокращения на их полные формы, используя short_word_dict. Для этого воспользуемся функцией, используемой в предыдущем пункте.\n",
        "\n",
        "5) Заменим эмотиконы (пример: \":)\" = \"happy\") на пробелы, используя emoticon_dict. Для этого воспользуемся функцией, используемой в предыдущем пункте.\n",
        "\n",
        "6) Заменим пунктуацию на пробелы, используя re.sub() и паттерн r'[^\\w\\s]'.\n",
        "\n",
        "7) Заменим спец. символы на пробелы, используя re.sub() и паттерн r'[^a-zA-Z0-9]'.\n",
        "\n",
        "8) Заменим числа на пробелы, используя re.sub() и паттерн r'[^a-zA-Z]'.\n",
        "\n",
        "9) Удалим из текста слова длиной в 1 символ, используя ' '.join([w for w in x.split() if len(w)>1]).\n",
        "\n",
        "10) Поделим твиты на токены с помощью nltk.tokenize.word_tokenize, создав новый столбец 'tweet_token'.\n",
        "\n",
        "11) Удалим стоп-слова из токенов, используя nltk.corpus.stopwords. Создадим столбец 'tweet_token_filtered' без стоп-слов.\n",
        "\n",
        "12) Применим стемминг к токенам с помощью nltk.stem.PorterStemmer. Создадим столбец 'tweet_stemmed' после применения стемминга.\n",
        "\n",
        "13) Применим лемматизацию к токенам с помощью nltk.stem.wordnet.WordNetLemmatizer. Создадим столбец 'tweet_lemmatized' после применения лемматизации.\n",
        "\n",
        "14) Сохраним результат предобработки в pickle-файл."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hde7N-Ntjtke"
      },
      "source": [
        "apostrophe_dict = {\n",
        "\"ain't\": \"am not / are not\",\n",
        "\"aren't\": \"are not / am not\",\n",
        "\"can't\": \"cannot\",\n",
        "\"can't've\": \"cannot have\",\n",
        "\"'cause\": \"because\",\n",
        "\"could've\": \"could have\",\n",
        "\"couldn't\": \"could not\",\n",
        "\"couldn't've\": \"could not have\",\n",
        "\"didn't\": \"did not\",\n",
        "\"doesn't\": \"does not\",\n",
        "\"don't\": \"do not\",\n",
        "\"hadn't\": \"had not\",\n",
        "\"hadn't've\": \"had not have\",\n",
        "\"hasn't\": \"has not\",\n",
        "\"haven't\": \"have not\",\n",
        "\"he'd\": \"he had / he would\",\n",
        "\"he'd've\": \"he would have\",\n",
        "\"he'll\": \"he shall / he will\",\n",
        "\"he'll've\": \"he shall have / he will have\",\n",
        "\"he's\": \"he has / he is\",\n",
        "\"how'd\": \"how did\",\n",
        "\"how'd'y\": \"how do you\",\n",
        "\"how'll\": \"how will\",\n",
        "\"how's\": \"how has / how is\",\n",
        "\"i'd\": \"I had / I would\",\n",
        "\"i'd've\": \"I would have\",\n",
        "\"i'll\": \"I shall / I will\",\n",
        "\"i'll've\": \"I shall have / I will have\",\n",
        "\"i'm\": \"I am\",\n",
        "\"i've\": \"I have\",\n",
        "\"isn't\": \"is not\",\n",
        "\"it'd\": \"it had / it would\",\n",
        "\"it'd've\": \"it would have\",\n",
        "\"it'll\": \"it shall / it will\",\n",
        "\"it'll've\": \"it shall have / it will have\",\n",
        "\"it's\": \"it has / it is\",\n",
        "\"let's\": \"let us\",\n",
        "\"ma'am\": \"madam\",\n",
        "\"mayn't\": \"may not\",\n",
        "\"might've\": \"might have\",\n",
        "\"mightn't\": \"might not\",\n",
        "\"mightn't've\": \"might not have\",\n",
        "\"must've\": \"must have\",\n",
        "\"mustn't\": \"must not\",\n",
        "\"mustn't've\": \"must not have\",\n",
        "\"needn't\": \"need not\",\n",
        "\"needn't've\": \"need not have\",\n",
        "\"o'clock\": \"of the clock\",\n",
        "\"oughtn't\": \"ought not\",\n",
        "\"oughtn't've\": \"ought not have\",\n",
        "\"shan't\": \"shall not\",\n",
        "\"sha'n't\": \"shall not\",\n",
        "\"shan't've\": \"shall not have\",\n",
        "\"she'd\": \"she had / she would\",\n",
        "\"she'd've\": \"she would have\",\n",
        "\"she'll\": \"she shall / she will\",\n",
        "\"she'll've\": \"she shall have / she will have\",\n",
        "\"she's\": \"she has / she is\",\n",
        "\"should've\": \"should have\",\n",
        "\"shouldn't\": \"should not\",\n",
        "\"shouldn't've\": \"should not have\",\n",
        "\"so've\": \"so have\",\n",
        "\"so's\": \"so as / so is\",\n",
        "\"that'd\": \"that would / that had\",\n",
        "\"that'd've\": \"that would have\",\n",
        "\"that's\": \"that has / that is\",\n",
        "\"there'd\": \"there had / there would\",\n",
        "\"there'd've\": \"there would have\",\n",
        "\"there's\": \"there has / there is\",\n",
        "\"they'd\": \"they had / they would\",\n",
        "\"they'd've\": \"they would have\",\n",
        "\"they'll\": \"they shall / they will\",\n",
        "\"they'll've\": \"they shall have / they will have\",\n",
        "\"they're\": \"they are\",\n",
        "\"they've\": \"they have\",\n",
        "\"to've\": \"to have\",\n",
        "\"wasn't\": \"was not\",\n",
        "\"we'd\": \"we had / we would\",\n",
        "\"we'd've\": \"we would have\",\n",
        "\"we'll\": \"we will\",\n",
        "\"we'll've\": \"we will have\",\n",
        "\"we're\": \"we are\",\n",
        "\"we've\": \"we have\",\n",
        "\"weren't\": \"were not\",\n",
        "\"what'll\": \"what shall / what will\",\n",
        "\"what'll've\": \"what shall have / what will have\",\n",
        "\"what're\": \"what are\",\n",
        "\"what's\": \"what has / what is\",\n",
        "\"what've\": \"what have\",\n",
        "\"when's\": \"when has / when is\",\n",
        "\"when've\": \"when have\",\n",
        "\"where'd\": \"where did\",\n",
        "\"where's\": \"where has / where is\",\n",
        "\"where've\": \"where have\",\n",
        "\"who'll\": \"who shall / who will\",\n",
        "\"who'll've\": \"who shall have / who will have\",\n",
        "\"who's\": \"who has / who is\",\n",
        "\"who've\": \"who have\",\n",
        "\"why's\": \"why has / why is\",\n",
        "\"why've\": \"why have\",\n",
        "\"will've\": \"will have\",\n",
        "\"won't\": \"will not\",\n",
        "\"won't've\": \"will not have\",\n",
        "\"would've\": \"would have\",\n",
        "\"wouldn't\": \"would not\",\n",
        "\"wouldn't've\": \"would not have\",\n",
        "\"y'all\": \"you all\",\n",
        "\"y'all'd\": \"you all would\",\n",
        "\"y'all'd've\": \"you all would have\",\n",
        "\"y'all're\": \"you all are\",\n",
        "\"y'all've\": \"you all have\",\n",
        "\"you'd\": \"you had / you would\",\n",
        "\"you'd've\": \"you would have\",\n",
        "\"you'll\": \"you shall / you will\",\n",
        "\"you'll've\": \"you shall have / you will have\",\n",
        "\"you're\": \"you are\",\n",
        "\"you've\": \"you have\"\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "short_word_dict = {\n",
        "\"121\": \"one to one\",\n",
        "\"a/s/l\": \"age, sex, location\",\n",
        "\"adn\": \"any day now\",\n",
        "\"afaik\": \"as far as I know\",\n",
        "\"afk\": \"away from keyboard\",\n",
        "\"aight\": \"alright\",\n",
        "\"alol\": \"actually laughing out loud\",\n",
        "\"b4\": \"before\",\n",
        "\"b4n\": \"bye for now\",\n",
        "\"bak\": \"back at the keyboard\",\n",
        "\"bf\": \"boyfriend\",\n",
        "\"bff\": \"best friends forever\",\n",
        "\"bfn\": \"bye for now\",\n",
        "\"bg\": \"big grin\",\n",
        "\"bta\": \"but then again\",\n",
        "\"btw\": \"by the way\",\n",
        "\"cid\": \"crying in disgrace\",\n",
        "\"cnp\": \"continued in my next post\",\n",
        "\"cp\": \"chat post\",\n",
        "\"cu\": \"see you\",\n",
        "\"cul\": \"see you later\",\n",
        "\"cul8r\": \"see you later\",\n",
        "\"cya\": \"bye\",\n",
        "\"cyo\": \"see you online\",\n",
        "\"dbau\": \"doing business as usual\",\n",
        "\"fud\": \"fear, uncertainty, and doubt\",\n",
        "\"fwiw\": \"for what it's worth\",\n",
        "\"fyi\": \"for your information\",\n",
        "\"g\": \"grin\",\n",
        "\"g2g\": \"got to go\",\n",
        "\"ga\": \"go ahead\",\n",
        "\"gal\": \"get a life\",\n",
        "\"gf\": \"girlfriend\",\n",
        "\"gfn\": \"gone for now\",\n",
        "\"gmbo\": \"giggling my butt off\",\n",
        "\"gmta\": \"great minds think alike\",\n",
        "\"h8\": \"hate\",\n",
        "\"hagn\": \"have a good night\",\n",
        "\"hdop\": \"help delete online predators\",\n",
        "\"hhis\": \"hanging head in shame\",\n",
        "\"iac\": \"in any case\",\n",
        "\"ianal\": \"I am not a lawyer\",\n",
        "\"ic\": \"I see\",\n",
        "\"idk\": \"I don't know\",\n",
        "\"imao\": \"in my arrogant opinion\",\n",
        "\"imnsho\": \"in my not so humble opinion\",\n",
        "\"imo\": \"in my opinion\",\n",
        "\"iow\": \"in other words\",\n",
        "\"ipn\": \"I’m posting naked\",\n",
        "\"irl\": \"in real life\",\n",
        "\"jk\": \"just kidding\",\n",
        "\"l8r\": \"later\",\n",
        "\"ld\": \"later, dude\",\n",
        "\"ldr\": \"long distance relationship\",\n",
        "\"llta\": \"lots and lots of thunderous applause\",\n",
        "\"lmao\": \"laugh my ass off\",\n",
        "\"lmirl\": \"let's meet in real life\",\n",
        "\"lol\": \"laugh out loud\",\n",
        "\"ltr\": \"longterm relationship\",\n",
        "\"lulab\": \"love you like a brother\",\n",
        "\"lulas\": \"love you like a sister\",\n",
        "\"luv\": \"love\",\n",
        "\"m/f\": \"male or female\",\n",
        "\"m8\": \"mate\",\n",
        "\"milf\": \"mother I would like to fuck\",\n",
        "\"oll\": \"online love\",\n",
        "\"omg\": \"oh my god\",\n",
        "\"otoh\": \"on the other hand\",\n",
        "\"pir\": \"parent in room\",\n",
        "\"ppl\": \"people\",\n",
        "\"r\": \"are\",\n",
        "\"rofl\": \"roll on the floor laughing\",\n",
        "\"rpg\": \"role playing games\",\n",
        "\"ru\": \"are you\",\n",
        "\"shid\": \"slaps head in disgust\",\n",
        "\"somy\": \"sick of me yet\",\n",
        "\"sot\": \"short of time\",\n",
        "\"thanx\": \"thanks\",\n",
        "\"thx\": \"thanks\",\n",
        "\"ttyl\": \"talk to you later\",\n",
        "\"u\": \"you\",\n",
        "\"ur\": \"you are\",\n",
        "\"uw\": \"you’re welcome\",\n",
        "\"wb\": \"welcome back\",\n",
        "\"wfm\": \"works for me\",\n",
        "\"wibni\": \"wouldn't it be nice if\",\n",
        "\"wtf\": \"what the fuck\",\n",
        "\"wtg\": \"way to go\",\n",
        "\"wtgp\": \"want to go private\",\n",
        "\"ym\": \"young man\",\n",
        "\"gr8\": \"great\"\n",
        "}\n",
        "\n",
        "\n",
        "emoticon_dict = {\n",
        "\":)\": \"happy\",\n",
        "\":‑)\": \"happy\",\n",
        "\":-]\": \"happy\",\n",
        "\":-3\": \"happy\",\n",
        "\":->\": \"happy\",\n",
        "\"8-)\": \"happy\",\n",
        "\":-}\": \"happy\",\n",
        "\":o)\": \"happy\",\n",
        "\":c)\": \"happy\",\n",
        "\":^)\": \"happy\",\n",
        "\"=]\": \"happy\",\n",
        "\"=)\": \"happy\",\n",
        "\"<3\": \"happy\",\n",
        "\":-(\": \"sad\",\n",
        "\":(\": \"sad\",\n",
        "\":c\": \"sad\",\n",
        "\":<\": \"sad\",\n",
        "\":[\": \"sad\",\n",
        "\">:[\": \"sad\",\n",
        "\":{\": \"sad\",\n",
        "\">:(\": \"sad\",\n",
        "\":-c\": \"sad\",\n",
        "\":-< \": \"sad\",\n",
        "\":-[\": \"sad\",\n",
        "\":-||\": \"sad\"\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JoUIp1njtks"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AUDDk3ajtkt",
        "outputId": "526d1a98-822e-4285-e17c-17b9a28834a8"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import warnings \n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "import os\n",
        "import html.parser  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Error loading punkt: <urlopen error [Errno 11001]\n",
            "[nltk_data]     getaddrinfo failed>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6ZVZvq2jtkv",
        "outputId": "402625d1-4164-4fda-953b-cd1913a4d225"
      },
      "source": [
        "train_df = pd.read_csv('train_tweets.csv')\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label                                              tweet\n",
              "0   1      0   @user when a father is dysfunctional and is s...\n",
              "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
              "2   3      0                                bihday your majesty\n",
              "3   4      0  #model   i love u take with u all the time in ...\n",
              "4   5      0             factsguide: society now    #motivation"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtA9kNHFjtkw",
        "outputId": "410b7b0f-4b19-4fa0-8886-a1f33da2626d"
      },
      "source": [
        "test_df = pd.read_csv('test_tweets.csv')\n",
        "test_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>31963</td>\n",
              "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31964</td>\n",
              "      <td>@user #white #supremacists want everyone to s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31965</td>\n",
              "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31966</td>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>31967</td>\n",
              "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                              tweet\n",
              "0  31963  #studiolife #aislife #requires #passion #dedic...\n",
              "1  31964   @user #white #supremacists want everyone to s...\n",
              "2  31965  safe ways to heal your #acne!!    #altwaystohe...\n",
              "3  31966  is the hp and the cursed child book up for res...\n",
              "4  31967    3rd #bihday to my amazing, hilarious #nephew..."
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6RV9yM0jtkx",
        "outputId": "c5e0ae8c-b79d-40a8-c7a5-dec4aaf645ff"
      },
      "source": [
        "combine_df = train_df.append(test_df, ignore_index = True, sort = False)\n",
        "combine_df.head(30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user camping tomorrow @user @user @user @use...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>the next school year is the year for exams.ð...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user @user welcome here !  i'm   it's so #gr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>0.0</td>\n",
              "      <td>â #ireland consumer price index (mom) climb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>we are so selfish. #orlando #standwithorlando ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>0.0</td>\n",
              "      <td>i get to see my daddy today!!   #80days #getti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>1.0</td>\n",
              "      <td>@user #cnn calls #michigan middle school 'buil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>15</td>\n",
              "      <td>1.0</td>\n",
              "      <td>no comment!  in #australia   #opkillingbay #se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>16</td>\n",
              "      <td>0.0</td>\n",
              "      <td>ouch...junior is angryð#got7 #junior #yugyo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>17</td>\n",
              "      <td>0.0</td>\n",
              "      <td>i am thankful for having a paner. #thankful #p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>18</td>\n",
              "      <td>1.0</td>\n",
              "      <td>retweet if you agree!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>19</td>\n",
              "      <td>0.0</td>\n",
              "      <td>its #friday! ð smiles all around via ig use...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>as we all know, essential oils are not made of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>21</td>\n",
              "      <td>0.0</td>\n",
              "      <td>#euro2016 people blaming ha for conceded goal ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>22</td>\n",
              "      <td>0.0</td>\n",
              "      <td>sad little dude..   #badday #coneofshame #cats...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>23</td>\n",
              "      <td>0.0</td>\n",
              "      <td>product of the day: happy man #wine tool  who'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>24</td>\n",
              "      <td>1.0</td>\n",
              "      <td>@user @user lumpy says i am a . prove it lumpy.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user #tgif   #ff to my #gamedev #indiedev #i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>26</td>\n",
              "      <td>0.0</td>\n",
              "      <td>beautiful sign by vendor 80 for $45.00!! #upsi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>27</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user all #smiles when #media is   !! ðð...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>28</td>\n",
              "      <td>0.0</td>\n",
              "      <td>we had a great panel on the mediatization of t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>29</td>\n",
              "      <td>0.0</td>\n",
              "      <td>happy father's day @user ðððð</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50 people went to nightclub to have a good nig...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    id  label                                              tweet\n",
              "0    1    0.0   @user when a father is dysfunctional and is s...\n",
              "1    2    0.0  @user @user thanks for #lyft credit i can't us...\n",
              "2    3    0.0                                bihday your majesty\n",
              "3    4    0.0  #model   i love u take with u all the time in ...\n",
              "4    5    0.0             factsguide: society now    #motivation\n",
              "5    6    0.0  [2/2] huge fan fare and big talking before the...\n",
              "6    7    0.0   @user camping tomorrow @user @user @user @use...\n",
              "7    8    0.0  the next school year is the year for exams.ð...\n",
              "8    9    0.0  we won!!! love the land!!! #allin #cavs #champ...\n",
              "9   10    0.0   @user @user welcome here !  i'm   it's so #gr...\n",
              "10  11    0.0   â #ireland consumer price index (mom) climb...\n",
              "11  12    0.0  we are so selfish. #orlando #standwithorlando ...\n",
              "12  13    0.0  i get to see my daddy today!!   #80days #getti...\n",
              "13  14    1.0  @user #cnn calls #michigan middle school 'buil...\n",
              "14  15    1.0  no comment!  in #australia   #opkillingbay #se...\n",
              "15  16    0.0  ouch...junior is angryð#got7 #junior #yugyo...\n",
              "16  17    0.0  i am thankful for having a paner. #thankful #p...\n",
              "17  18    1.0                             retweet if you agree! \n",
              "18  19    0.0  its #friday! ð smiles all around via ig use...\n",
              "19  20    0.0  as we all know, essential oils are not made of...\n",
              "20  21    0.0  #euro2016 people blaming ha for conceded goal ...\n",
              "21  22    0.0  sad little dude..   #badday #coneofshame #cats...\n",
              "22  23    0.0  product of the day: happy man #wine tool  who'...\n",
              "23  24    1.0    @user @user lumpy says i am a . prove it lumpy.\n",
              "24  25    0.0   @user #tgif   #ff to my #gamedev #indiedev #i...\n",
              "25  26    0.0  beautiful sign by vendor 80 for $45.00!! #upsi...\n",
              "26  27    0.0   @user all #smiles when #media is   !! ðð...\n",
              "27  28    0.0  we had a great panel on the mediatization of t...\n",
              "28  29    0.0        happy father's day @user ðððð  \n",
              "29  30    0.0  50 people went to nightclub to have a good nig..."
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxoAeAs3jtkz",
        "outputId": "dba268d2-2a70-459b-e071-0cd5c73e7255"
      },
      "source": [
        "print(combine_df.info())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 49159 entries, 0 to 49158\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   id      49159 non-null  int64  \n",
            " 1   label   31962 non-null  float64\n",
            " 2   tweet   49159 non-null  object \n",
            "dtypes: float64(1), int64(1), object(1)\n",
            "memory usage: 1.1+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-pvwg8Ojtk0"
      },
      "source": [
        "0.\tЗаменим html-сущности (к примеру: < > &). \"<\" заменим на “<” и \"&\" заменим на “&”)\"\"\". Сделаем это с помощью HTMLParser.unescape(). Всю предобработку делаем в новом столбце 'clean_tweet'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mg_mpwR8jtk1"
      },
      "source": [
        "combine_df['clean_tweet'] = [html.parser.HTMLParser().unescape(str(tweet)) for tweet in combine_df['tweet']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFX5PQ7qjtk2",
        "outputId": "966bf26d-bc79-43be-f1fa-dd3b1f99c396"
      },
      "source": [
        "combine_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>clean_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label                                              tweet  \\\n",
              "0   1    0.0   @user when a father is dysfunctional and is s...   \n",
              "1   2    0.0  @user @user thanks for #lyft credit i can't us...   \n",
              "2   3    0.0                                bihday your majesty   \n",
              "3   4    0.0  #model   i love u take with u all the time in ...   \n",
              "4   5    0.0             factsguide: society now    #motivation   \n",
              "\n",
              "                                         clean_tweet  \n",
              "0   @user when a father is dysfunctional and is s...  \n",
              "1  @user @user thanks for #lyft credit i can't us...  \n",
              "2                                bihday your majesty  \n",
              "3  #model   i love u take with u all the time in ...  \n",
              "4             factsguide: society now    #motivation  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKP-0G_yjtk3"
      },
      "source": [
        "1. Удалим @user из всех твитов с помощью паттерна \"@[\\w]*\". Для этого создадим функцию: \n",
        " - для того, чтобы найти все вхождения паттерна в тексте, необходимо использовать re.findall(pattern, input_txt)\n",
        " - для для замены @user на пробел, необходимо использовать re.sub()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6ohANE0jtk4"
      },
      "source": [
        "combine_df['clean_tweet'] = [re.sub(r\"@[\\w]*\", ' ', str(tweet)) for tweet in combine_df['clean_tweet']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7MHJbwRjtk4",
        "outputId": "22e578d7-a57c-4308-f2a0-ec159602aa2b"
      },
      "source": [
        "combine_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>clean_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>when a father is dysfunctional and is so se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>thanks for #lyft credit i can't use cause ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label                                              tweet  \\\n",
              "0   1    0.0   @user when a father is dysfunctional and is s...   \n",
              "1   2    0.0  @user @user thanks for #lyft credit i can't us...   \n",
              "2   3    0.0                                bihday your majesty   \n",
              "3   4    0.0  #model   i love u take with u all the time in ...   \n",
              "4   5    0.0             factsguide: society now    #motivation   \n",
              "\n",
              "                                         clean_tweet  \n",
              "0     when a father is dysfunctional and is so se...  \n",
              "1      thanks for #lyft credit i can't use cause ...  \n",
              "2                                bihday your majesty  \n",
              "3  #model   i love u take with u all the time in ...  \n",
              "4             factsguide: society now    #motivation  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAnWccm8jtk6"
      },
      "source": [
        "2. Изменим регистр твитов на нижний с помощью .lower()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9m_8jYXjtk6"
      },
      "source": [
        "combine_df['clean_tweet'] = [str(tweet).lower() for tweet in combine_df['clean_tweet']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yijYwsWVjtk7",
        "outputId": "530a41df-ef69-47f1-dc6e-bec24b2b7949"
      },
      "source": [
        "combine_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>clean_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>when a father is dysfunctional and is so se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>thanks for #lyft credit i can't use cause ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label                                              tweet  \\\n",
              "0   1    0.0   @user when a father is dysfunctional and is s...   \n",
              "1   2    0.0  @user @user thanks for #lyft credit i can't us...   \n",
              "2   3    0.0                                bihday your majesty   \n",
              "3   4    0.0  #model   i love u take with u all the time in ...   \n",
              "4   5    0.0             factsguide: society now    #motivation   \n",
              "\n",
              "                                         clean_tweet  \n",
              "0     when a father is dysfunctional and is so se...  \n",
              "1      thanks for #lyft credit i can't use cause ...  \n",
              "2                                bihday your majesty  \n",
              "3  #model   i love u take with u all the time in ...  \n",
              "4             factsguide: society now    #motivation  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIcENv5Wjtk8"
      },
      "source": [
        "3. Заменим сокращения с апострофами (пример: ain't, can't) на пробел, используя apostrophe_dict. Для этого необходимо сделать функцию: для каждого слова в тексте проверить (for word in text.split()), если слово есть в словаре apostrophe_dict в качестве ключа (сокращенного слова), то заменить ключ на значение (полную версию слова)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZnsi167jtk8"
      },
      "source": [
        "def lookup(s, dict):\n",
        "    return dict.get(s, s)\n",
        "\n",
        "def expand(s_text, dict):\n",
        "    return ' '.join(lookup(s,dict) for s in s_text.split())\n",
        "\n",
        "\n",
        "combine_df['clean_tweet'] = [expand(str(tweet), apostrophe_dict) for tweet in combine_df['clean_tweet']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnjZNCFljtk9",
        "outputId": "27b1502e-afaf-4705-e002-58cb60a26e7b"
      },
      "source": [
        "combine_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>clean_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>when a father is dysfunctional and is so selfi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>thanks for #lyft credit i cannot use cause the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>#model i love u take with u all the time in ur...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>factsguide: society now #motivation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label                                              tweet  \\\n",
              "0   1    0.0   @user when a father is dysfunctional and is s...   \n",
              "1   2    0.0  @user @user thanks for #lyft credit i can't us...   \n",
              "2   3    0.0                                bihday your majesty   \n",
              "3   4    0.0  #model   i love u take with u all the time in ...   \n",
              "4   5    0.0             factsguide: society now    #motivation   \n",
              "\n",
              "                                         clean_tweet  \n",
              "0  when a father is dysfunctional and is so selfi...  \n",
              "1  thanks for #lyft credit i cannot use cause the...  \n",
              "2                                bihday your majesty  \n",
              "3  #model i love u take with u all the time in ur...  \n",
              "4                factsguide: society now #motivation  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sHJ8KQWjtk-"
      },
      "source": [
        "4. Заменим сокращения на их полные формы, используя short_word_dict. Для этого воспользуемся функцией, используемой в предыдущем пункте."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AerKyJ8Xjtk-"
      },
      "source": [
        "combine_df['clean_tweet'] = [expand(str(tweet), short_word_dict) for tweet in combine_df['clean_tweet']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpILR2ACjtk_",
        "outputId": "f2faeb46-189a-4c6f-cef6-c190157c4741"
      },
      "source": [
        "combine_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>clean_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>when a father is dysfunctional and is so selfi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>thanks for #lyft credit i cannot use cause the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>#model i love you take with you all the time i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>factsguide: society now #motivation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label                                              tweet  \\\n",
              "0   1    0.0   @user when a father is dysfunctional and is s...   \n",
              "1   2    0.0  @user @user thanks for #lyft credit i can't us...   \n",
              "2   3    0.0                                bihday your majesty   \n",
              "3   4    0.0  #model   i love u take with u all the time in ...   \n",
              "4   5    0.0             factsguide: society now    #motivation   \n",
              "\n",
              "                                         clean_tweet  \n",
              "0  when a father is dysfunctional and is so selfi...  \n",
              "1  thanks for #lyft credit i cannot use cause the...  \n",
              "2                                bihday your majesty  \n",
              "3  #model i love you take with you all the time i...  \n",
              "4                factsguide: society now #motivation  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81jXEL5Qjtk_"
      },
      "source": [
        "5. Заменим эмотиконы (пример: \":)\" = \"happy\") на пробелы, используя emoticon_dict. Для этого воспользуемся функцией, используемой в предыдущем пункте."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3S4D4qbijtlA"
      },
      "source": [
        "combine_df['clean_tweet'] = [expand(str(tweet), emoticon_dict) for tweet in combine_df['clean_tweet']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFI98tqzjtlA",
        "outputId": "7ac9a4b7-5201-40fc-f6f7-f64183840169"
      },
      "source": [
        "combine_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>clean_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>when a father is dysfunctional and is so selfi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>thanks for #lyft credit i cannot use cause the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>#model i love you take with you all the time i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>factsguide: society now #motivation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label                                              tweet  \\\n",
              "0   1    0.0   @user when a father is dysfunctional and is s...   \n",
              "1   2    0.0  @user @user thanks for #lyft credit i can't us...   \n",
              "2   3    0.0                                bihday your majesty   \n",
              "3   4    0.0  #model   i love u take with u all the time in ...   \n",
              "4   5    0.0             factsguide: society now    #motivation   \n",
              "\n",
              "                                         clean_tweet  \n",
              "0  when a father is dysfunctional and is so selfi...  \n",
              "1  thanks for #lyft credit i cannot use cause the...  \n",
              "2                                bihday your majesty  \n",
              "3  #model i love you take with you all the time i...  \n",
              "4                factsguide: society now #motivation  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5h0MbYyjtlB"
      },
      "source": [
        "6. Заменим пунктуацию на пробелы, используя re.sub() и паттерн r'[^\\w\\s]'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tpd1f7bjtlB"
      },
      "source": [
        "combine_df['clean_tweet'] = [re.sub(r'[^\\w\\s]', ' ', str(tweet)) for tweet in combine_df['clean_tweet']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hs258w1KjtlB"
      },
      "source": [
        "# Дополнительное пребразование после удаления спец символов\n",
        "combine_df['clean_tweet'] = [expand(str(tweet), short_word_dict) for tweet in combine_df['clean_tweet']] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bnx6uqFjtlC",
        "outputId": "83cd522e-3781-4ef5-ad73-c747b3ee578b"
      },
      "source": [
        "combine_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>clean_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>when a father is dysfunctional and is so selfi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>thanks for lyft credit i cannot use cause they...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>model i love you take with you all the time in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>factsguide society now motivation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label                                              tweet  \\\n",
              "0   1    0.0   @user when a father is dysfunctional and is s...   \n",
              "1   2    0.0  @user @user thanks for #lyft credit i can't us...   \n",
              "2   3    0.0                                bihday your majesty   \n",
              "3   4    0.0  #model   i love u take with u all the time in ...   \n",
              "4   5    0.0             factsguide: society now    #motivation   \n",
              "\n",
              "                                         clean_tweet  \n",
              "0  when a father is dysfunctional and is so selfi...  \n",
              "1  thanks for lyft credit i cannot use cause they...  \n",
              "2                                bihday your majesty  \n",
              "3  model i love you take with you all the time in...  \n",
              "4                  factsguide society now motivation  "
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PvGihAwjtlC"
      },
      "source": [
        "7. Заменим спец. символы на пробелы, используя re.sub() и паттерн r'[^a-zA-Z0-9]'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gL8gvPr4jtlD"
      },
      "source": [
        "combine_df['clean_tweet'] = [re.sub(r'[^a-zA-Z0-9]', ' ', str(tweet)) for tweet in combine_df['clean_tweet']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpieb-xLjtlD",
        "outputId": "ba9f2788-0305-4046-bb3c-e0f4a5c08a77"
      },
      "source": [
        "combine_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>clean_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>when a father is dysfunctional and is so selfi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>thanks for lyft credit i cannot use cause they...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>model i love you take with you all the time in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>factsguide society now motivation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label                                              tweet  \\\n",
              "0   1    0.0   @user when a father is dysfunctional and is s...   \n",
              "1   2    0.0  @user @user thanks for #lyft credit i can't us...   \n",
              "2   3    0.0                                bihday your majesty   \n",
              "3   4    0.0  #model   i love u take with u all the time in ...   \n",
              "4   5    0.0             factsguide: society now    #motivation   \n",
              "\n",
              "                                         clean_tweet  \n",
              "0  when a father is dysfunctional and is so selfi...  \n",
              "1  thanks for lyft credit i cannot use cause they...  \n",
              "2                                bihday your majesty  \n",
              "3  model i love you take with you all the time in...  \n",
              "4                  factsguide society now motivation  "
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlZZ-yhijtlD"
      },
      "source": [
        "8. Заменим числа на пробелы, используя re.sub() и паттерн r'[^a-zA-Z]'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WokiZbvEjtlE"
      },
      "source": [
        "combine_df['clean_tweet'] = [re.sub(r'[^a-zA-Z]', ' ', str(tweet)) for tweet in combine_df['clean_tweet']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLLXjyZyjtlE",
        "outputId": "8e417fbe-027c-44b1-cbfa-f7177be269ff"
      },
      "source": [
        "combine_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>clean_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>when a father is dysfunctional and is so selfi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>thanks for lyft credit i cannot use cause they...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>model i love you take with you all the time in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>factsguide society now motivation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label                                              tweet  \\\n",
              "0   1    0.0   @user when a father is dysfunctional and is s...   \n",
              "1   2    0.0  @user @user thanks for #lyft credit i can't us...   \n",
              "2   3    0.0                                bihday your majesty   \n",
              "3   4    0.0  #model   i love u take with u all the time in ...   \n",
              "4   5    0.0             factsguide: society now    #motivation   \n",
              "\n",
              "                                         clean_tweet  \n",
              "0  when a father is dysfunctional and is so selfi...  \n",
              "1  thanks for lyft credit i cannot use cause they...  \n",
              "2                                bihday your majesty  \n",
              "3  model i love you take with you all the time in...  \n",
              "4                  factsguide society now motivation  "
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-O_qgbeijtlE"
      },
      "source": [
        "9. Удалим из текста слова длиной в 1 символ, используя ' '.join([w for w in x.split() if len(w)>1])"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkSF9RoijtlF"
      },
      "source": [
        "combine_df['clean_tweet'] = [' '.join([w for w in tweet.split() if len(w)>1]) for tweet in combine_df['clean_tweet']]    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtumvtRqjtlF",
        "outputId": "1d1d4fd3-09b6-43cf-d0ab-0fc0be00e325"
      },
      "source": [
        "combine_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>clean_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>when father is dysfunctional and is so selfish...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>thanks for lyft credit cannot use cause they d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>model love you take with you all the time in ur</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>factsguide society now motivation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label                                              tweet  \\\n",
              "0   1    0.0   @user when a father is dysfunctional and is s...   \n",
              "1   2    0.0  @user @user thanks for #lyft credit i can't us...   \n",
              "2   3    0.0                                bihday your majesty   \n",
              "3   4    0.0  #model   i love u take with u all the time in ...   \n",
              "4   5    0.0             factsguide: society now    #motivation   \n",
              "\n",
              "                                         clean_tweet  \n",
              "0  when father is dysfunctional and is so selfish...  \n",
              "1  thanks for lyft credit cannot use cause they d...  \n",
              "2                                bihday your majesty  \n",
              "3    model love you take with you all the time in ur  \n",
              "4                  factsguide society now motivation  "
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnta-A6cjtlG"
      },
      "source": [
        "10. Поделим твиты на токены с помощью nltk.tokenize.word_tokenize, создав новый столбец 'tweet_token'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOVVvATkjtlH"
      },
      "source": [
        "# Повторил замену сокращений, тк не все замены сработали в пп 4 из-за спец символов\n",
        "combine_df['clean_tweet'] = [expand(str(tweet), short_word_dict) for tweet in combine_df['clean_tweet']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrAj9a_3jtlI"
      },
      "source": [
        "combine_df['tweet_token'] = [nltk.tokenize.word_tokenize(tweet) for tweet in combine_df['clean_tweet']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ie1ZNzHVjtlI",
        "outputId": "47aac046-fb54-4f82-ae8a-608613f77573"
      },
      "source": [
        "combine_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>clean_tweet</th>\n",
              "      <th>tweet_token</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>when father is dysfunctional and is so selfish...</td>\n",
              "      <td>[when, father, is, dysfunctional, and, is, so,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>thanks for lyft credit cannot use cause they d...</td>\n",
              "      <td>[thanks, for, lyft, credit, can, not, use, cau...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>[bihday, your, majesty]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>model love you take with you all the time in y...</td>\n",
              "      <td>[model, love, you, take, with, you, all, the, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>factsguide society now motivation</td>\n",
              "      <td>[factsguide, society, now, motivation]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label                                              tweet  \\\n",
              "0   1    0.0   @user when a father is dysfunctional and is s...   \n",
              "1   2    0.0  @user @user thanks for #lyft credit i can't us...   \n",
              "2   3    0.0                                bihday your majesty   \n",
              "3   4    0.0  #model   i love u take with u all the time in ...   \n",
              "4   5    0.0             factsguide: society now    #motivation   \n",
              "\n",
              "                                         clean_tweet  \\\n",
              "0  when father is dysfunctional and is so selfish...   \n",
              "1  thanks for lyft credit cannot use cause they d...   \n",
              "2                                bihday your majesty   \n",
              "3  model love you take with you all the time in y...   \n",
              "4                  factsguide society now motivation   \n",
              "\n",
              "                                         tweet_token  \n",
              "0  [when, father, is, dysfunctional, and, is, so,...  \n",
              "1  [thanks, for, lyft, credit, can, not, use, cau...  \n",
              "2                            [bihday, your, majesty]  \n",
              "3  [model, love, you, take, with, you, all, the, ...  \n",
              "4             [factsguide, society, now, motivation]  "
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oITbC8pXjtlJ"
      },
      "source": [
        "11. Удалим стоп-слова из токенов, используя nltk.corpus.stopwords. Создадим столбец 'tweet_token_filtered' без стоп-слов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rM8gceNUjtlJ"
      },
      "source": [
        "mystopwords = stopwords.words('english')\n",
        "def remove_stopwords(token, stop_words = mystopwords):\n",
        "    return [t for t in token if t not in stop_words]\n",
        "combine_df['tweet_token_filtered'] = [remove_stopwords(tweet) for tweet in combine_df['tweet_token']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YPXaYEyjtlJ",
        "outputId": "30a984ef-7e48-48e8-cc9f-ddb34fdf18b0"
      },
      "source": [
        "combine_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>clean_tweet</th>\n",
              "      <th>tweet_token</th>\n",
              "      <th>tweet_token_filtered</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>when father is dysfunctional and is so selfish...</td>\n",
              "      <td>[when, father, is, dysfunctional, and, is, so,...</td>\n",
              "      <td>[father, dysfunctional, selfish, drags, kids, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>thanks for lyft credit cannot use cause they d...</td>\n",
              "      <td>[thanks, for, lyft, credit, can, not, use, cau...</td>\n",
              "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>[bihday, your, majesty]</td>\n",
              "      <td>[bihday, majesty]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>model love you take with you all the time in y...</td>\n",
              "      <td>[model, love, you, take, with, you, all, the, ...</td>\n",
              "      <td>[model, love, take, time]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>factsguide society now motivation</td>\n",
              "      <td>[factsguide, society, now, motivation]</td>\n",
              "      <td>[factsguide, society, motivation]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label                                              tweet  \\\n",
              "0   1    0.0   @user when a father is dysfunctional and is s...   \n",
              "1   2    0.0  @user @user thanks for #lyft credit i can't us...   \n",
              "2   3    0.0                                bihday your majesty   \n",
              "3   4    0.0  #model   i love u take with u all the time in ...   \n",
              "4   5    0.0             factsguide: society now    #motivation   \n",
              "\n",
              "                                         clean_tweet  \\\n",
              "0  when father is dysfunctional and is so selfish...   \n",
              "1  thanks for lyft credit cannot use cause they d...   \n",
              "2                                bihday your majesty   \n",
              "3  model love you take with you all the time in y...   \n",
              "4                  factsguide society now motivation   \n",
              "\n",
              "                                         tweet_token  \\\n",
              "0  [when, father, is, dysfunctional, and, is, so,...   \n",
              "1  [thanks, for, lyft, credit, can, not, use, cau...   \n",
              "2                            [bihday, your, majesty]   \n",
              "3  [model, love, you, take, with, you, all, the, ...   \n",
              "4             [factsguide, society, now, motivation]   \n",
              "\n",
              "                                tweet_token_filtered  \n",
              "0  [father, dysfunctional, selfish, drags, kids, ...  \n",
              "1  [thanks, lyft, credit, use, cause, offer, whee...  \n",
              "2                                  [bihday, majesty]  \n",
              "3                          [model, love, take, time]  \n",
              "4                  [factsguide, society, motivation]  "
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sD0nPXhyjtlK"
      },
      "source": [
        "12. Применим стемминг к токенам с помощью nltk.stem.PorterStemmer. Создадим столбец 'tweet_stemmed' после применения стемминга."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyOW3sEGjtlL"
      },
      "source": [
        "def Stemmer(token):\n",
        "    stemmer = PorterStemmer()\n",
        "    return [stemmer.stem(word) for word in token]\n",
        "combine_df['tweet_stemmed'] = [Stemmer(token) for token in combine_df['tweet_token_filtered']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPnu7FSyjtlL",
        "outputId": "5621da34-f0f2-4a6a-adfd-a36bc672a03b"
      },
      "source": [
        "combine_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>clean_tweet</th>\n",
              "      <th>tweet_token</th>\n",
              "      <th>tweet_token_filtered</th>\n",
              "      <th>tweet_stemmed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>when father is dysfunctional and is so selfish...</td>\n",
              "      <td>[when, father, is, dysfunctional, and, is, so,...</td>\n",
              "      <td>[father, dysfunctional, selfish, drags, kids, ...</td>\n",
              "      <td>[father, dysfunct, selfish, drag, kid, dysfunc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>thanks for lyft credit cannot use cause they d...</td>\n",
              "      <td>[thanks, for, lyft, credit, can, not, use, cau...</td>\n",
              "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
              "      <td>[thank, lyft, credit, use, caus, offer, wheelc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>[bihday, your, majesty]</td>\n",
              "      <td>[bihday, majesty]</td>\n",
              "      <td>[bihday, majesti]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>model love you take with you all the time in y...</td>\n",
              "      <td>[model, love, you, take, with, you, all, the, ...</td>\n",
              "      <td>[model, love, take, time]</td>\n",
              "      <td>[model, love, take, time]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>factsguide society now motivation</td>\n",
              "      <td>[factsguide, society, now, motivation]</td>\n",
              "      <td>[factsguide, society, motivation]</td>\n",
              "      <td>[factsguid, societi, motiv]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label                                              tweet  \\\n",
              "0   1    0.0   @user when a father is dysfunctional and is s...   \n",
              "1   2    0.0  @user @user thanks for #lyft credit i can't us...   \n",
              "2   3    0.0                                bihday your majesty   \n",
              "3   4    0.0  #model   i love u take with u all the time in ...   \n",
              "4   5    0.0             factsguide: society now    #motivation   \n",
              "\n",
              "                                         clean_tweet  \\\n",
              "0  when father is dysfunctional and is so selfish...   \n",
              "1  thanks for lyft credit cannot use cause they d...   \n",
              "2                                bihday your majesty   \n",
              "3  model love you take with you all the time in y...   \n",
              "4                  factsguide society now motivation   \n",
              "\n",
              "                                         tweet_token  \\\n",
              "0  [when, father, is, dysfunctional, and, is, so,...   \n",
              "1  [thanks, for, lyft, credit, can, not, use, cau...   \n",
              "2                            [bihday, your, majesty]   \n",
              "3  [model, love, you, take, with, you, all, the, ...   \n",
              "4             [factsguide, society, now, motivation]   \n",
              "\n",
              "                                tweet_token_filtered  \\\n",
              "0  [father, dysfunctional, selfish, drags, kids, ...   \n",
              "1  [thanks, lyft, credit, use, cause, offer, whee...   \n",
              "2                                  [bihday, majesty]   \n",
              "3                          [model, love, take, time]   \n",
              "4                  [factsguide, society, motivation]   \n",
              "\n",
              "                                       tweet_stemmed  \n",
              "0  [father, dysfunct, selfish, drag, kid, dysfunc...  \n",
              "1  [thank, lyft, credit, use, caus, offer, wheelc...  \n",
              "2                                  [bihday, majesti]  \n",
              "3                          [model, love, take, time]  \n",
              "4                        [factsguid, societi, motiv]  "
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHoXooTbjtlM"
      },
      "source": [
        "13. Применим лемматизацию к токенам с помощью nltk.stem.wordnet.WordNetLemmatizer. Создадим столбец 'tweet_lemmatized' после применения лемматизации."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iENic1djtlN"
      },
      "source": [
        "def Lemmatizer(token, pos='n'):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    return [lemmatizer.lemmatize(word, pos) for word in token]\n",
        "combine_df['tweet_lemmatized'] = [Lemmatizer(token) for token in combine_df['tweet_token_filtered']] # Существительные\n",
        "combine_df['tweet_lemmatized'] = [Lemmatizer(token, 'v') for token in combine_df['tweet_token_filtered']] # Глаголы"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RftpiwwjtlN",
        "outputId": "ccedffe2-20ff-44a0-acb8-cf4c7d34070c"
      },
      "source": [
        "combine_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>clean_tweet</th>\n",
              "      <th>tweet_token</th>\n",
              "      <th>tweet_token_filtered</th>\n",
              "      <th>tweet_stemmed</th>\n",
              "      <th>tweet_lemmatized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>when father is dysfunctional and is so selfish...</td>\n",
              "      <td>[when, father, is, dysfunctional, and, is, so,...</td>\n",
              "      <td>[father, dysfunctional, selfish, drags, kids, ...</td>\n",
              "      <td>[father, dysfunct, selfish, drag, kid, dysfunc...</td>\n",
              "      <td>[father, dysfunctional, selfish, drag, kid, dy...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>thanks for lyft credit cannot use cause they d...</td>\n",
              "      <td>[thanks, for, lyft, credit, can, not, use, cau...</td>\n",
              "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
              "      <td>[thank, lyft, credit, use, caus, offer, wheelc...</td>\n",
              "      <td>[thank, lyft, credit, use, cause, offer, wheel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>[bihday, your, majesty]</td>\n",
              "      <td>[bihday, majesty]</td>\n",
              "      <td>[bihday, majesti]</td>\n",
              "      <td>[bihday, majesty]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>model love you take with you all the time in y...</td>\n",
              "      <td>[model, love, you, take, with, you, all, the, ...</td>\n",
              "      <td>[model, love, take, time]</td>\n",
              "      <td>[model, love, take, time]</td>\n",
              "      <td>[model, love, take, time]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>factsguide society now motivation</td>\n",
              "      <td>[factsguide, society, now, motivation]</td>\n",
              "      <td>[factsguide, society, motivation]</td>\n",
              "      <td>[factsguid, societi, motiv]</td>\n",
              "      <td>[factsguide, society, motivation]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label                                              tweet  \\\n",
              "0   1    0.0   @user when a father is dysfunctional and is s...   \n",
              "1   2    0.0  @user @user thanks for #lyft credit i can't us...   \n",
              "2   3    0.0                                bihday your majesty   \n",
              "3   4    0.0  #model   i love u take with u all the time in ...   \n",
              "4   5    0.0             factsguide: society now    #motivation   \n",
              "\n",
              "                                         clean_tweet  \\\n",
              "0  when father is dysfunctional and is so selfish...   \n",
              "1  thanks for lyft credit cannot use cause they d...   \n",
              "2                                bihday your majesty   \n",
              "3  model love you take with you all the time in y...   \n",
              "4                  factsguide society now motivation   \n",
              "\n",
              "                                         tweet_token  \\\n",
              "0  [when, father, is, dysfunctional, and, is, so,...   \n",
              "1  [thanks, for, lyft, credit, can, not, use, cau...   \n",
              "2                            [bihday, your, majesty]   \n",
              "3  [model, love, you, take, with, you, all, the, ...   \n",
              "4             [factsguide, society, now, motivation]   \n",
              "\n",
              "                                tweet_token_filtered  \\\n",
              "0  [father, dysfunctional, selfish, drags, kids, ...   \n",
              "1  [thanks, lyft, credit, use, cause, offer, whee...   \n",
              "2                                  [bihday, majesty]   \n",
              "3                          [model, love, take, time]   \n",
              "4                  [factsguide, society, motivation]   \n",
              "\n",
              "                                       tweet_stemmed  \\\n",
              "0  [father, dysfunct, selfish, drag, kid, dysfunc...   \n",
              "1  [thank, lyft, credit, use, caus, offer, wheelc...   \n",
              "2                                  [bihday, majesti]   \n",
              "3                          [model, love, take, time]   \n",
              "4                        [factsguid, societi, motiv]   \n",
              "\n",
              "                                    tweet_lemmatized  \n",
              "0  [father, dysfunctional, selfish, drag, kid, dy...  \n",
              "1  [thank, lyft, credit, use, cause, offer, wheel...  \n",
              "2                                  [bihday, majesty]  \n",
              "3                          [model, love, take, time]  \n",
              "4                  [factsguide, society, motivation]  "
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UezRCnI_jtlO"
      },
      "source": [
        "14. Сохраним результат предобработки в pickle-файл."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YSToUILjtlO"
      },
      "source": [
        "combine_df.to_pickle('df')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmbDQ9KsjtlO"
      },
      "source": [
        "## Homework_lesson_2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fj6iwzjjjtlP"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aX9W8JljtlP"
      },
      "source": [
        "df = pd.read_pickle('df')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oG-hjK3KjtlP"
      },
      "source": [
        "1. Создайте мешок слов с помощью sklearn.feature_extraction.text.CountVectorizer.fit_transform(). Применим его к 'tweet_stemmed' и 'tweet_lemmatized' отдельно.\n",
        "●\tИгнорируем слова, частота которых в документе строго превышает порог 0.9 с помощью max_df.\n",
        "\n",
        "●\tОграничим количество слов, попадающий в мешок, с помощью max_features = 1000.\n",
        "\n",
        "●\tИсключим стоп-слова с помощью stop_words='english'.\n",
        "\n",
        "●\tОтобразим Bag-of-Words модель как DataFrame. columns необходимо извлечь с помощью CountVectorizer.get_feature_names().\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIY7IUs5jtlQ"
      },
      "source": [
        "count_vectorizer = CountVectorizer(max_df=0.9, max_features = 1000, stop_words='english')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mx7BuMljtlQ"
      },
      "source": [
        "df['tweet_lemmatized_bow'] = df['tweet_lemmatized'].apply(lambda x: ' '.join([token for token in x]))\n",
        "bag_of_words_lemmatized = count_vectorizer.fit_transform(df['tweet_lemmatized_bow'].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdReI6GcjtlQ",
        "outputId": "e85d0b0a-79ab-4f85-c598-45216cff92b5"
      },
      "source": [
        "feature_names = count_vectorizer.get_feature_names()\n",
        "pd.DataFrame(bag_of_words_lemmatized.toarray(), columns = feature_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>able</th>\n",
              "      <th>absolutely</th>\n",
              "      <th>accept</th>\n",
              "      <th>account</th>\n",
              "      <th>act</th>\n",
              "      <th>action</th>\n",
              "      <th>actor</th>\n",
              "      <th>actually</th>\n",
              "      <th>adapt</th>\n",
              "      <th>add</th>\n",
              "      <th>...</th>\n",
              "      <th>yesterday</th>\n",
              "      <th>yo</th>\n",
              "      <th>yoga</th>\n",
              "      <th>york</th>\n",
              "      <th>young</th>\n",
              "      <th>youth</th>\n",
              "      <th>youtube</th>\n",
              "      <th>yr</th>\n",
              "      <th>yrs</th>\n",
              "      <th>yummy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49154</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49155</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49156</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49157</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49158</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>49159 rows × 1000 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       able  absolutely  accept  account  act  action  actor  actually  adapt  \\\n",
              "0         0           0       0        0    0       0      0         0      0   \n",
              "1         0           0       0        0    0       0      0         0      0   \n",
              "2         0           0       0        0    0       0      0         0      0   \n",
              "3         0           0       0        0    0       0      0         0      0   \n",
              "4         0           0       0        0    0       0      0         0      0   \n",
              "...     ...         ...     ...      ...  ...     ...    ...       ...    ...   \n",
              "49154     0           0       0        0    0       0      0         0      0   \n",
              "49155     0           0       0        0    0       0      0         0      0   \n",
              "49156     0           0       0        0    0       0      0         0      0   \n",
              "49157     0           0       0        0    0       0      0         0      0   \n",
              "49158     0           0       0        0    0       0      0         0      0   \n",
              "\n",
              "       add  ...  yesterday  yo  yoga  york  young  youth  youtube  yr  yrs  \\\n",
              "0        0  ...          0   0     0     0      0      0        0   0    0   \n",
              "1        0  ...          0   0     0     0      0      0        0   0    0   \n",
              "2        0  ...          0   0     0     0      0      0        0   0    0   \n",
              "3        0  ...          0   0     0     0      0      0        0   0    0   \n",
              "4        0  ...          0   0     0     0      0      0        0   0    0   \n",
              "...    ...  ...        ...  ..   ...   ...    ...    ...      ...  ..  ...   \n",
              "49154    0  ...          0   0     0     0      0      0        0   0    0   \n",
              "49155    0  ...          0   0     0     0      0      0        0   0    0   \n",
              "49156    0  ...          0   0     0     0      0      0        0   0    0   \n",
              "49157    0  ...          0   0     0     0      0      0        0   0    0   \n",
              "49158    0  ...          0   0     0     0      0      0        0   0    0   \n",
              "\n",
              "       yummy  \n",
              "0          0  \n",
              "1          0  \n",
              "2          0  \n",
              "3          0  \n",
              "4          0  \n",
              "...      ...  \n",
              "49154      0  \n",
              "49155      0  \n",
              "49156      0  \n",
              "49157      0  \n",
              "49158      0  \n",
              "\n",
              "[49159 rows x 1000 columns]"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZT5eMu-jtlR"
      },
      "source": [
        "df['tweet_stemmed_bow'] = df['tweet_stemmed'].apply(lambda x: ' '.join([token for token in x]))\n",
        "bag_of_words_stemmed = count_vectorizer.fit_transform(df['tweet_lemmatized_bow'].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCa2ihhcjtlR",
        "outputId": "3cc87ada-9a9e-4121-e7bf-5460ff7603b1"
      },
      "source": [
        "feature_names = count_vectorizer.get_feature_names()\n",
        "pd.DataFrame(bag_of_words_stemmed.toarray(), columns = feature_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>able</th>\n",
              "      <th>absolutely</th>\n",
              "      <th>accept</th>\n",
              "      <th>account</th>\n",
              "      <th>act</th>\n",
              "      <th>action</th>\n",
              "      <th>actor</th>\n",
              "      <th>actually</th>\n",
              "      <th>adapt</th>\n",
              "      <th>add</th>\n",
              "      <th>...</th>\n",
              "      <th>yesterday</th>\n",
              "      <th>yo</th>\n",
              "      <th>yoga</th>\n",
              "      <th>york</th>\n",
              "      <th>young</th>\n",
              "      <th>youth</th>\n",
              "      <th>youtube</th>\n",
              "      <th>yr</th>\n",
              "      <th>yrs</th>\n",
              "      <th>yummy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49154</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49155</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49156</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49157</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49158</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>49159 rows × 1000 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       able  absolutely  accept  account  act  action  actor  actually  adapt  \\\n",
              "0         0           0       0        0    0       0      0         0      0   \n",
              "1         0           0       0        0    0       0      0         0      0   \n",
              "2         0           0       0        0    0       0      0         0      0   \n",
              "3         0           0       0        0    0       0      0         0      0   \n",
              "4         0           0       0        0    0       0      0         0      0   \n",
              "...     ...         ...     ...      ...  ...     ...    ...       ...    ...   \n",
              "49154     0           0       0        0    0       0      0         0      0   \n",
              "49155     0           0       0        0    0       0      0         0      0   \n",
              "49156     0           0       0        0    0       0      0         0      0   \n",
              "49157     0           0       0        0    0       0      0         0      0   \n",
              "49158     0           0       0        0    0       0      0         0      0   \n",
              "\n",
              "       add  ...  yesterday  yo  yoga  york  young  youth  youtube  yr  yrs  \\\n",
              "0        0  ...          0   0     0     0      0      0        0   0    0   \n",
              "1        0  ...          0   0     0     0      0      0        0   0    0   \n",
              "2        0  ...          0   0     0     0      0      0        0   0    0   \n",
              "3        0  ...          0   0     0     0      0      0        0   0    0   \n",
              "4        0  ...          0   0     0     0      0      0        0   0    0   \n",
              "...    ...  ...        ...  ..   ...   ...    ...    ...      ...  ..  ...   \n",
              "49154    0  ...          0   0     0     0      0      0        0   0    0   \n",
              "49155    0  ...          0   0     0     0      0      0        0   0    0   \n",
              "49156    0  ...          0   0     0     0      0      0        0   0    0   \n",
              "49157    0  ...          0   0     0     0      0      0        0   0    0   \n",
              "49158    0  ...          0   0     0     0      0      0        0   0    0   \n",
              "\n",
              "       yummy  \n",
              "0          0  \n",
              "1          0  \n",
              "2          0  \n",
              "3          0  \n",
              "4          0  \n",
              "...      ...  \n",
              "49154      0  \n",
              "49155      0  \n",
              "49156      0  \n",
              "49157      0  \n",
              "49158      0  \n",
              "\n",
              "[49159 rows x 1000 columns]"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljepm7sRjtlR"
      },
      "source": [
        "2. Создайте мешок слов с помощью sklearn.feature_extraction.text.TfidfVectorizer.fit_transform(). Применим его к 'tweet_stemmed' и 'tweet_lemmatized' отдельно.\n",
        "\n",
        "●\tИгнорируем слова, частота которых в документе строго превышает порог 0.9 с помощью max_df.\n",
        "\n",
        "●\tОграничим количество слов, попадающий в мешок, с помощью max_features = 1000.\n",
        "\n",
        "●\tИсключим стоп-слова с помощью stop_words='english'.\n",
        "\n",
        "●\tОтобразим Bag-of-Words модель как DataFrame. columns необходимо извлечь с помощью TfidfVectorizer.get_feature_names().\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXuIVo-vjtlS"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdEq_0r7jtlS"
      },
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(max_df=0.9, max_features = 1000, stop_words='english')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANMfN-YujtlT"
      },
      "source": [
        "#df['tweet_lemmatized_bow'] = df['tweet_lemmatized'].apply(lambda x: ' '.join([token for token in x]))\n",
        "bag_of_words_lemmatized_tfidf = tfidf_vectorizer.fit_transform(df['tweet_lemmatized_bow'].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kf7rSBrljtlU",
        "outputId": "fd95943c-840a-4444-f310-5f2b0e3f48bf"
      },
      "source": [
        "feature_names = tfidf_vectorizer.get_feature_names()\n",
        "pd.DataFrame(bag_of_words_lemmatized_tfidf.toarray(), columns = feature_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>able</th>\n",
              "      <th>absolutely</th>\n",
              "      <th>accept</th>\n",
              "      <th>account</th>\n",
              "      <th>act</th>\n",
              "      <th>action</th>\n",
              "      <th>actor</th>\n",
              "      <th>actually</th>\n",
              "      <th>adapt</th>\n",
              "      <th>add</th>\n",
              "      <th>...</th>\n",
              "      <th>yesterday</th>\n",
              "      <th>yo</th>\n",
              "      <th>yoga</th>\n",
              "      <th>york</th>\n",
              "      <th>young</th>\n",
              "      <th>youth</th>\n",
              "      <th>youtube</th>\n",
              "      <th>yr</th>\n",
              "      <th>yrs</th>\n",
              "      <th>yummy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49154</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49155</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49156</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49157</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49158</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>49159 rows × 1000 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       able  absolutely  accept  account  act  action  actor  actually  adapt  \\\n",
              "0       0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0    0.0   \n",
              "1       0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0    0.0   \n",
              "2       0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0    0.0   \n",
              "3       0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0    0.0   \n",
              "4       0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0    0.0   \n",
              "...     ...         ...     ...      ...  ...     ...    ...       ...    ...   \n",
              "49154   0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0    0.0   \n",
              "49155   0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0    0.0   \n",
              "49156   0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0    0.0   \n",
              "49157   0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0    0.0   \n",
              "49158   0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0    0.0   \n",
              "\n",
              "       add  ...  yesterday   yo  yoga  york  young  youth  youtube   yr  yrs  \\\n",
              "0      0.0  ...        0.0  0.0   0.0   0.0    0.0    0.0      0.0  0.0  0.0   \n",
              "1      0.0  ...        0.0  0.0   0.0   0.0    0.0    0.0      0.0  0.0  0.0   \n",
              "2      0.0  ...        0.0  0.0   0.0   0.0    0.0    0.0      0.0  0.0  0.0   \n",
              "3      0.0  ...        0.0  0.0   0.0   0.0    0.0    0.0      0.0  0.0  0.0   \n",
              "4      0.0  ...        0.0  0.0   0.0   0.0    0.0    0.0      0.0  0.0  0.0   \n",
              "...    ...  ...        ...  ...   ...   ...    ...    ...      ...  ...  ...   \n",
              "49154  0.0  ...        0.0  0.0   0.0   0.0    0.0    0.0      0.0  0.0  0.0   \n",
              "49155  0.0  ...        0.0  0.0   0.0   0.0    0.0    0.0      0.0  0.0  0.0   \n",
              "49156  0.0  ...        0.0  0.0   0.0   0.0    0.0    0.0      0.0  0.0  0.0   \n",
              "49157  0.0  ...        0.0  0.0   0.0   0.0    0.0    0.0      0.0  0.0  0.0   \n",
              "49158  0.0  ...        0.0  0.0   0.0   0.0    0.0    0.0      0.0  0.0  0.0   \n",
              "\n",
              "       yummy  \n",
              "0        0.0  \n",
              "1        0.0  \n",
              "2        0.0  \n",
              "3        0.0  \n",
              "4        0.0  \n",
              "...      ...  \n",
              "49154    0.0  \n",
              "49155    0.0  \n",
              "49156    0.0  \n",
              "49157    0.0  \n",
              "49158    0.0  \n",
              "\n",
              "[49159 rows x 1000 columns]"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8qyJwFljtlU"
      },
      "source": [
        "#df['tweet_stemmed_bow'] = df['tweet_stemmed'].apply(lambda x: ' '.join([token for token in x]))\n",
        "bag_of_words_stemmed_tfidf = tfidf_vectorizer.fit_transform(df['tweet_lemmatized_bow'].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHJes2QojtlV",
        "outputId": "4ac25d55-f1a7-4984-9f80-da804946d23f"
      },
      "source": [
        "feature_names = tfidf_vectorizer.get_feature_names()\n",
        "pd.DataFrame(bag_of_words_stemmed_tfidf.toarray(), columns = feature_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>able</th>\n",
              "      <th>absolutely</th>\n",
              "      <th>accept</th>\n",
              "      <th>account</th>\n",
              "      <th>act</th>\n",
              "      <th>action</th>\n",
              "      <th>actor</th>\n",
              "      <th>actually</th>\n",
              "      <th>adapt</th>\n",
              "      <th>add</th>\n",
              "      <th>...</th>\n",
              "      <th>yesterday</th>\n",
              "      <th>yo</th>\n",
              "      <th>yoga</th>\n",
              "      <th>york</th>\n",
              "      <th>young</th>\n",
              "      <th>youth</th>\n",
              "      <th>youtube</th>\n",
              "      <th>yr</th>\n",
              "      <th>yrs</th>\n",
              "      <th>yummy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49154</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49155</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49156</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49157</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49158</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>49159 rows × 1000 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       able  absolutely  accept  account  act  action  actor  actually  adapt  \\\n",
              "0       0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0    0.0   \n",
              "1       0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0    0.0   \n",
              "2       0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0    0.0   \n",
              "3       0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0    0.0   \n",
              "4       0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0    0.0   \n",
              "...     ...         ...     ...      ...  ...     ...    ...       ...    ...   \n",
              "49154   0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0    0.0   \n",
              "49155   0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0    0.0   \n",
              "49156   0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0    0.0   \n",
              "49157   0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0    0.0   \n",
              "49158   0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0    0.0   \n",
              "\n",
              "       add  ...  yesterday   yo  yoga  york  young  youth  youtube   yr  yrs  \\\n",
              "0      0.0  ...        0.0  0.0   0.0   0.0    0.0    0.0      0.0  0.0  0.0   \n",
              "1      0.0  ...        0.0  0.0   0.0   0.0    0.0    0.0      0.0  0.0  0.0   \n",
              "2      0.0  ...        0.0  0.0   0.0   0.0    0.0    0.0      0.0  0.0  0.0   \n",
              "3      0.0  ...        0.0  0.0   0.0   0.0    0.0    0.0      0.0  0.0  0.0   \n",
              "4      0.0  ...        0.0  0.0   0.0   0.0    0.0    0.0      0.0  0.0  0.0   \n",
              "...    ...  ...        ...  ...   ...   ...    ...    ...      ...  ...  ...   \n",
              "49154  0.0  ...        0.0  0.0   0.0   0.0    0.0    0.0      0.0  0.0  0.0   \n",
              "49155  0.0  ...        0.0  0.0   0.0   0.0    0.0    0.0      0.0  0.0  0.0   \n",
              "49156  0.0  ...        0.0  0.0   0.0   0.0    0.0    0.0      0.0  0.0  0.0   \n",
              "49157  0.0  ...        0.0  0.0   0.0   0.0    0.0    0.0      0.0  0.0  0.0   \n",
              "49158  0.0  ...        0.0  0.0   0.0   0.0    0.0    0.0      0.0  0.0  0.0   \n",
              "\n",
              "       yummy  \n",
              "0        0.0  \n",
              "1        0.0  \n",
              "2        0.0  \n",
              "3        0.0  \n",
              "4        0.0  \n",
              "...      ...  \n",
              "49154    0.0  \n",
              "49155    0.0  \n",
              "49156    0.0  \n",
              "49157    0.0  \n",
              "49158    0.0  \n",
              "\n",
              "[49159 rows x 1000 columns]"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LE4r4_sHjtlV"
      },
      "source": [
        "3. Проверьте ваши векторайзеры на корпусе который использовали на вебинаре, составьте таблицу метод векторизации и скор который вы получили (в методах векторизации по изменяйте параметры что бы добиться лучшего скора) обратите внимание как падает/растёт скор при уменьшении количества фичей, и изменении параметров, так же попробуйте применить к векторайзерам PCA для сокращения размерности посмотрите на качество сделайте выводы\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VV_RI7fJjtlV",
        "outputId": "da5ea3d8-6d47-48fd-da8f-739e45118c5e"
      },
      "source": [
        "# Загружаем данные\n",
        "data = open('corpus', encoding=\"utf8\").read()\n",
        "labels, texts = [], []\n",
        "for i, line in enumerate(data.split(\"\\n\")):\n",
        "    content = line.split()\n",
        "    labels.append(content[0])\n",
        "    texts.append(\" \".join(content[1:]))\n",
        "\n",
        "# создаем df\n",
        "trainDF = pd.DataFrame()\n",
        "trainDF['text'] = texts\n",
        "trainDF['label'] = labels\n",
        "trainDF.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Stuning even for the non-gamer: This sound tra...</td>\n",
              "      <td>__label__2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The best soundtrack ever to anything.: I'm rea...</td>\n",
              "      <td>__label__2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Amazing!: This soundtrack is my favorite music...</td>\n",
              "      <td>__label__2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Excellent Soundtrack: I truly like this soundt...</td>\n",
              "      <td>__label__2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
              "      <td>__label__2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text       label\n",
              "0  Stuning even for the non-gamer: This sound tra...  __label__2\n",
              "1  The best soundtrack ever to anything.: I'm rea...  __label__2\n",
              "2  Amazing!: This soundtrack is my favorite music...  __label__2\n",
              "3  Excellent Soundtrack: I truly like this soundt...  __label__2\n",
              "4  Remember, Pull Your Jaw Off The Floor After He...  __label__2"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1jHo1e3jtlW"
      },
      "source": [
        "# Таблица результатов\n",
        "models_results_1 = {\n",
        "    'vectorizer': [],\n",
        "    'max_df': [],\n",
        "    'max_features': [],\n",
        "    'score': []\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjurcBnijtlX"
      },
      "source": [
        "from sklearn import model_selection, preprocessing, linear_model\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(trainDF['text'], trainDF['label'])\n",
        "\n",
        "# labelEncode целевую переменную\n",
        "encoder = preprocessing.LabelEncoder()\n",
        "train_y = encoder.fit_transform(train_y)\n",
        "valid_y = encoder.fit_transform(valid_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UDXzVxVjtlX",
        "outputId": "37ae87c3-9268-49e3-c753-8d2e5d35b200"
      },
      "source": [
        "vectorisers_list = ['TfidfVectorizer', 'CountVectorizer']\n",
        "max_df_list = [0.5, 0.7, 0.8, 0.9, 1]\n",
        "max_features_list = [100, 200, 500, 1000, 2000]\n",
        "for vectoriser in vectorisers_list:\n",
        "    for df in max_df_list:\n",
        "        for feat in max_features_list:\n",
        "            if vectoriser == 'TfidfVectorizer':\n",
        "                vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_df=df, max_features=feat)\n",
        "                vect.fit(trainDF['text'])\n",
        "\n",
        "                xtrain =  vect.transform(train_x)\n",
        "                xvalid =  vect.transform(valid_x)\n",
        "\n",
        "                classifier = linear_model.LogisticRegression()\n",
        "                classifier.fit(xtrain, train_y)\n",
        "                predictions = classifier.predict(xvalid)\n",
        "                score = accuracy_score(valid_y, predictions)\n",
        "                models_results_1['vectorizer'].append(vectoriser)\n",
        "                models_results_1['max_df'].append(df)\n",
        "                models_results_1['max_features'].append(feat)\n",
        "                models_results_1['score'].append(score)\n",
        "            else:\n",
        "                vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_df=df, max_features=feat)\n",
        "                vect.fit(trainDF['text'])\n",
        "\n",
        "                xtrain =  vect.transform(train_x)\n",
        "                xvalid =  vect.transform(valid_x)\n",
        "\n",
        "                classifier = linear_model.LogisticRegression()\n",
        "                classifier.fit(xtrain, train_y)\n",
        "                predictions = classifier.predict(xvalid)\n",
        "                score = accuracy_score(valid_y, predictions)\n",
        "                models_results_1['vectorizer'].append(vectoriser)\n",
        "                models_results_1['max_df'].append(df)\n",
        "                models_results_1['max_features'].append(feat)\n",
        "                models_results_1['score'].append(score)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "D:\\GeekBrains\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "D:\\GeekBrains\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "D:\\GeekBrains\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "D:\\GeekBrains\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "D:\\GeekBrains\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "D:\\GeekBrains\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "D:\\GeekBrains\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "D:\\GeekBrains\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "D:\\GeekBrains\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "D:\\GeekBrains\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "D:\\GeekBrains\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "D:\\GeekBrains\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYXpQvB8jtlY",
        "outputId": "1db21a10-2b6b-4dbb-db4d-25f9490535d1"
      },
      "source": [
        "df_1 = pd.DataFrame(data=models_results_1).sort_values('score', ascending=False)\n",
        "df_1.head(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vectorizer</th>\n",
              "      <th>max_df</th>\n",
              "      <th>max_features</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>TfidfVectorizer</td>\n",
              "      <td>0.8</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.8668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>TfidfVectorizer</td>\n",
              "      <td>0.7</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.8656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TfidfVectorizer</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.8656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>TfidfVectorizer</td>\n",
              "      <td>0.9</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.8652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>CountVectorizer</td>\n",
              "      <td>0.9</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.8604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>CountVectorizer</td>\n",
              "      <td>0.8</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.8592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>CountVectorizer</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.8580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>CountVectorizer</td>\n",
              "      <td>0.7</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.8580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>TfidfVectorizer</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1000</td>\n",
              "      <td>0.8572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>TfidfVectorizer</td>\n",
              "      <td>0.7</td>\n",
              "      <td>1000</td>\n",
              "      <td>0.8568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>TfidfVectorizer</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1000</td>\n",
              "      <td>0.8552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TfidfVectorizer</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1000</td>\n",
              "      <td>0.8532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>CountVectorizer</td>\n",
              "      <td>0.7</td>\n",
              "      <td>1000</td>\n",
              "      <td>0.8428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>CountVectorizer</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1000</td>\n",
              "      <td>0.8428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>CountVectorizer</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1000</td>\n",
              "      <td>0.8424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>CountVectorizer</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1000</td>\n",
              "      <td>0.8420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>CountVectorizer</td>\n",
              "      <td>0.9</td>\n",
              "      <td>500</td>\n",
              "      <td>0.8340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>TfidfVectorizer</td>\n",
              "      <td>0.7</td>\n",
              "      <td>500</td>\n",
              "      <td>0.8320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>CountVectorizer</td>\n",
              "      <td>0.8</td>\n",
              "      <td>500</td>\n",
              "      <td>0.8312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TfidfVectorizer</td>\n",
              "      <td>0.5</td>\n",
              "      <td>500</td>\n",
              "      <td>0.8308</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         vectorizer  max_df  max_features   score\n",
              "14  TfidfVectorizer     0.8          2000  0.8668\n",
              "9   TfidfVectorizer     0.7          2000  0.8656\n",
              "4   TfidfVectorizer     0.5          2000  0.8656\n",
              "19  TfidfVectorizer     0.9          2000  0.8652\n",
              "44  CountVectorizer     0.9          2000  0.8604\n",
              "39  CountVectorizer     0.8          2000  0.8592\n",
              "29  CountVectorizer     0.5          2000  0.8580\n",
              "34  CountVectorizer     0.7          2000  0.8580\n",
              "13  TfidfVectorizer     0.8          1000  0.8572\n",
              "8   TfidfVectorizer     0.7          1000  0.8568\n",
              "18  TfidfVectorizer     0.9          1000  0.8552\n",
              "3   TfidfVectorizer     0.5          1000  0.8532\n",
              "33  CountVectorizer     0.7          1000  0.8428\n",
              "43  CountVectorizer     0.9          1000  0.8428\n",
              "38  CountVectorizer     0.8          1000  0.8424\n",
              "28  CountVectorizer     0.5          1000  0.8420\n",
              "42  CountVectorizer     0.9           500  0.8340\n",
              "7   TfidfVectorizer     0.7           500  0.8320\n",
              "37  CountVectorizer     0.8           500  0.8312\n",
              "2   TfidfVectorizer     0.5           500  0.8308"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ya6N1Q5qjtlZ"
      },
      "source": [
        "С увеличением max_features ожидаемо растёт score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPpDl8xqjtlZ"
      },
      "source": [
        "from sklearn.decomposition import TruncatedSVD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3Y36AEgjtlZ"
      },
      "source": [
        "# Таблица результатов с РСА\n",
        "models_results_2 = {\n",
        "    'vectorizer': [],\n",
        "    'n_components': [],\n",
        "    'score': []\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30sndnNdjtlZ"
      },
      "source": [
        "# Таблица результатов с РСА\n",
        "models_results_2 = {\n",
        "    'vectorizer': [],\n",
        "    'max_df': [],\n",
        "    'max_features': [],\n",
        "    'n_components': [],\n",
        "    'score': []\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wv2yxgrSjtla"
      },
      "source": [
        "vectorisers_list = ['TfidfVectorizer with pca', 'CountVectorizer with pca']\n",
        "n_components = [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 30, 40]\n",
        "max_df_list = [0.5, 0.7, 0.8, 0.9, 1]\n",
        "max_features_list = [100, 200, 500, 1000, 2000]\n",
        "for vectoriser in vectorisers_list:\n",
        "    for df in max_df_list:\n",
        "        for feat in max_features_list:\n",
        "            for n in n_components:\n",
        "                if vectoriser == 'TfidfVectorizer with pca':\n",
        "                    vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_df=df, max_features=feat)\n",
        "                    vect.fit(trainDF['text'])\n",
        "\n",
        "                    xtrain =  vect.transform(train_x)\n",
        "                    xvalid =  vect.transform(valid_x)\n",
        "\n",
        "                    svd = TruncatedSVD(n_components=n, random_state=42)\n",
        "                    pca_t = svd.fit_transform(xtrain)\n",
        "                    pca_v = svd.fit_transform(xvalid)\n",
        "\n",
        "                    classifier = linear_model.LogisticRegression()\n",
        "                    classifier.fit(pca_t, train_y)\n",
        "                    predictions = classifier.predict(pca_v)\n",
        "                    score = accuracy_score(valid_y, predictions)\n",
        "                    models_results_2['vectorizer'].append(vectoriser)\n",
        "                    models_results_2['max_df'].append(df)\n",
        "                    models_results_2['max_features'].append(feat)\n",
        "                    models_results_2['n_components'].append(n)\n",
        "                    models_results_2['score'].append(score)\n",
        "                else:\n",
        "                    vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_df=df, max_features=feat)\n",
        "                    vect.fit(trainDF['text'])\n",
        "\n",
        "                    xtrain =  vect.transform(train_x)\n",
        "                    xvalid =  vect.transform(valid_x)\n",
        "\n",
        "                    svd = TruncatedSVD(n_components=n, random_state=42)\n",
        "                    pca_t = svd.fit_transform(xtrain)\n",
        "                    pca_v = svd.fit_transform(xvalid)\n",
        "\n",
        "                    classifier = linear_model.LogisticRegression()\n",
        "                    classifier.fit(pca_t, train_y)\n",
        "                    predictions = classifier.predict(pca_v)\n",
        "                    score = accuracy_score(valid_y, predictions)\n",
        "                    models_results_2['vectorizer'].append(vectoriser)\n",
        "                    models_results_2['max_df'].append(df)\n",
        "                    models_results_2['max_features'].append(feat)\n",
        "                    models_results_2['n_components'].append(n)\n",
        "                    models_results_2['score'].append(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lezkcAgljtlb",
        "outputId": "aa768647-2f26-423b-c192-7ee8fa23f7c9"
      },
      "source": [
        "df_2 = pd.DataFrame(data=models_results_2).sort_values('score', ascending=False)\n",
        "df_2.head(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vectorizer</th>\n",
              "      <th>max_df</th>\n",
              "      <th>max_features</th>\n",
              "      <th>n_components</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>TfidfVectorizer with pca</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1000</td>\n",
              "      <td>9</td>\n",
              "      <td>0.7384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>TfidfVectorizer with pca</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1000</td>\n",
              "      <td>11</td>\n",
              "      <td>0.7336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>TfidfVectorizer with pca</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1000</td>\n",
              "      <td>7</td>\n",
              "      <td>0.7268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>TfidfVectorizer with pca</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1000</td>\n",
              "      <td>8</td>\n",
              "      <td>0.7204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>TfidfVectorizer with pca</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1000</td>\n",
              "      <td>15</td>\n",
              "      <td>0.7192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>TfidfVectorizer with pca</td>\n",
              "      <td>0.7</td>\n",
              "      <td>500</td>\n",
              "      <td>8</td>\n",
              "      <td>0.7172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>TfidfVectorizer with pca</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1000</td>\n",
              "      <td>40</td>\n",
              "      <td>0.7144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>TfidfVectorizer with pca</td>\n",
              "      <td>0.5</td>\n",
              "      <td>500</td>\n",
              "      <td>13</td>\n",
              "      <td>0.7144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>TfidfVectorizer with pca</td>\n",
              "      <td>0.7</td>\n",
              "      <td>500</td>\n",
              "      <td>15</td>\n",
              "      <td>0.7124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>TfidfVectorizer with pca</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1000</td>\n",
              "      <td>30</td>\n",
              "      <td>0.7108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>TfidfVectorizer with pca</td>\n",
              "      <td>0.5</td>\n",
              "      <td>500</td>\n",
              "      <td>12</td>\n",
              "      <td>0.7104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>TfidfVectorizer with pca</td>\n",
              "      <td>0.5</td>\n",
              "      <td>500</td>\n",
              "      <td>15</td>\n",
              "      <td>0.7080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>TfidfVectorizer with pca</td>\n",
              "      <td>0.5</td>\n",
              "      <td>500</td>\n",
              "      <td>14</td>\n",
              "      <td>0.7060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227</th>\n",
              "      <td>TfidfVectorizer with pca</td>\n",
              "      <td>0.9</td>\n",
              "      <td>500</td>\n",
              "      <td>12</td>\n",
              "      <td>0.7056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>TfidfVectorizer with pca</td>\n",
              "      <td>0.5</td>\n",
              "      <td>500</td>\n",
              "      <td>8</td>\n",
              "      <td>0.7052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>TfidfVectorizer with pca</td>\n",
              "      <td>0.5</td>\n",
              "      <td>200</td>\n",
              "      <td>7</td>\n",
              "      <td>0.7044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>TfidfVectorizer with pca</td>\n",
              "      <td>0.5</td>\n",
              "      <td>200</td>\n",
              "      <td>12</td>\n",
              "      <td>0.7036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>TfidfVectorizer with pca</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1000</td>\n",
              "      <td>20</td>\n",
              "      <td>0.7028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>TfidfVectorizer with pca</td>\n",
              "      <td>0.5</td>\n",
              "      <td>500</td>\n",
              "      <td>20</td>\n",
              "      <td>0.7028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>TfidfVectorizer with pca</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1000</td>\n",
              "      <td>12</td>\n",
              "      <td>0.7016</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   vectorizer  max_df  max_features  n_components   score\n",
              "42   TfidfVectorizer with pca     0.5          1000             9  0.7384\n",
              "44   TfidfVectorizer with pca     0.5          1000            11  0.7336\n",
              "40   TfidfVectorizer with pca     0.5          1000             7  0.7268\n",
              "41   TfidfVectorizer with pca     0.5          1000             8  0.7204\n",
              "48   TfidfVectorizer with pca     0.5          1000            15  0.7192\n",
              "93   TfidfVectorizer with pca     0.7           500             8  0.7172\n",
              "51   TfidfVectorizer with pca     0.5          1000            40  0.7144\n",
              "33   TfidfVectorizer with pca     0.5           500            13  0.7144\n",
              "100  TfidfVectorizer with pca     0.7           500            15  0.7124\n",
              "50   TfidfVectorizer with pca     0.5          1000            30  0.7108\n",
              "32   TfidfVectorizer with pca     0.5           500            12  0.7104\n",
              "35   TfidfVectorizer with pca     0.5           500            15  0.7080\n",
              "34   TfidfVectorizer with pca     0.5           500            14  0.7060\n",
              "227  TfidfVectorizer with pca     0.9           500            12  0.7056\n",
              "28   TfidfVectorizer with pca     0.5           500             8  0.7052\n",
              "14   TfidfVectorizer with pca     0.5           200             7  0.7044\n",
              "19   TfidfVectorizer with pca     0.5           200            12  0.7036\n",
              "49   TfidfVectorizer with pca     0.5          1000            20  0.7028\n",
              "36   TfidfVectorizer with pca     0.5           500            20  0.7028\n",
              "45   TfidfVectorizer with pca     0.5          1000            12  0.7016"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1apVsp2jtlc"
      },
      "source": [
        "Модель потеряла 13% score при использовании PCA, но при этом размерность была значительно снижена."
      ]
    }
  ]
}